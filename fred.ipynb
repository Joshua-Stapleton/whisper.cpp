{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import importlib\n",
    "import traceback\n",
    "import asyncio\n",
    "import os.path\n",
    "import io\n",
    "from datetime import datetime\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "import pickle\n",
    "from googleapiclient.errors import HttpError\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from tools.gpt_functions import generate_gpt4_response, generate_gpt4_response_async\n",
    "from tools.notification_functions import send_email, send_email_async\n",
    "for k,v in list(sys.modules.items()):\n",
    "    if k.startswith('tools') or k.startswith('.env'):\n",
    "        importlib.reload(v)\n",
    "\n",
    "\n",
    "# Load the environment variables from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "FOLDER_ID_TO_EMAIL = {\n",
    "    '1Qdrs4naVqJH2KIcr1maQ3vuq5DGuDK-G': 'scha@cancelledfoodcoupon.com',\n",
    "    '1AUSninKPQ9mZXFaISKAXPRv4RzpB9oNx': 'mike@mantisnetworks.co',\n",
    "    '1UHH7ZuFS8anO_NIFqe25SHqPun_stmeQ': 'clint@mantisnetworks.co',\n",
    "    '1ibUUpCy74WUROr5TSa-pLYLYM6ivUUmZ': 'loren@mantisnetworks.co',\n",
    "    '1SwickgZ8MDK_BIyL7IhSn0oZdVxAMzHE': 'joshua.stapleton.ai@gmail.com',\n",
    "    '1BO0yHZO8CfrSzX2SvWhD1uUbq_M3L7X2': 'bartdenil12@gmail.com',\n",
    "    '1sA77uMfOftiR8njcATy_IFBng8-apXv0': 'brensuzy@gmail.com',\n",
    "    '1csJ4knxQ5Yp4vESB85ZMxkL8e5qKKkE_': 'brendanjstapleton@gmail.com',\n",
    "}\n",
    "\n",
    "# folder ids from google drive\n",
    "FOLDER_NAME_TO_FOLDER_ID = {\n",
    "    'audios_scha': '1Qdrs4naVqJH2KIcr1maQ3vuq5DGuDK-G',\n",
    "    'audios_mike': '1AUSninKPQ9mZXFaISKAXPRv4RzpB9oNx',\n",
    "    'audios_clint': '1UHH7ZuFS8anO_NIFqe25SHqPun_stmeQ',\n",
    "    'audios_loren': '1ibUUpCy74WUROr5TSa-pLYLYM6ivUUmZ',\n",
    "    'audios_josh': '1SwickgZ8MDK_BIyL7IhSn0oZdVxAMzHE',\n",
    "    'audios_bart': '1BO0yHZO8CfrSzX2SvWhD1uUbq_M3L7X2',\n",
    "    'audios_mom': '1sA77uMfOftiR8njcATy_IFBng8-apXv0',\n",
    "    'audios_dad': '1csJ4knxQ5Yp4vESB85ZMxkL8e5qKKkE_'\n",
    "}\n",
    "\n",
    "FOLDER_NAME_TO_EMAIL = {folder_name: FOLDER_ID_TO_EMAIL[folder_id] for folder_name, folder_id in FOLDER_NAME_TO_FOLDER_ID.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def whisper_async(target_file:str, local_folder:str):\n",
    "    base = os.path.splitext(target_file)[0]\n",
    "    input_file = os.path.join(local_folder, target_file)\n",
    "    output_file = os.path.join(local_folder, f\"{base}.wav\")\n",
    "\n",
    "    if target_file.endswith('.m4a') or target_file.endswith('.mp3'):\n",
    "        print(f\"Processing {target_file}...\")\n",
    "        process = await asyncio.create_subprocess_exec(\n",
    "            'ffmpeg', '-i', input_file, '-ar', '16000', output_file, \n",
    "            stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT\n",
    "        )\n",
    "        await process.wait()\n",
    "    elif target_file.endswith('.wav'): # move straight to F\n",
    "        print(f\"Processing {target_file} file as .wav...\")\n",
    "    else:\n",
    "        print(f\"Unsupported file format: {target_file}\")\n",
    "        return\n",
    "\n",
    "    print(\"Running whisper to get transcript...\")\n",
    "    process = await asyncio.create_subprocess_exec(\n",
    "        './main', '-f', output_file, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT\n",
    "    )\n",
    "    await process.wait()\n",
    "\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fred_async(filename:str):\n",
    "    print(\"FILENAME:\", filename)\n",
    "    receiving_email_address = FOLDER_NAME_TO_EMAIL.get(filename.split('/')[0])\n",
    "    try:\n",
    "        if (\"transcript\" in filename.lower()) or ('transcribe' in filename.lower()): # simply send the transcribed text\n",
    "            print(\"Sending transcript...\")\n",
    "            with open(filename, 'r') as file:\n",
    "                transcript = file.read()\n",
    "            # Code to send the transcript\n",
    "            asyncio.create_task(send_email_async(os.environ.get('SENDING_EMAIL_ADDRESS'), 'joshua.stapleton.ai@gmail.com', \"FRED response for \" + filename, \"TRANSCRIPT:\\n\" + transcript, os.environ.get('EMAIL_PASSWORD')))\n",
    "\n",
    "            if receiving_email_address:  # If an email address was found\n",
    "                asyncio.create_task(send_email_async(os.environ.get('SENDING_EMAIL_ADDRESS'), receiving_email_address, \"FRED response for \" + filename, \"TRANSCRIPT:\\n\" + transcript, os.environ.get('EMAIL_PASSWORD')))\n",
    "\n",
    "        else:\n",
    "            print(\"Running Fred...\")\n",
    "            with open(filename, 'r') as file:\n",
    "                transcript = file.read()\n",
    "                response = await generate_gpt4_response_async(transcript, 1) # we await this because we can't send the email until we get a response from the API\n",
    "                asyncio.create_task(send_email_async(os.environ.get('SENDING_EMAIL_ADDRESS'), 'joshua.stapleton.ai@gmail.com', \"FRED response for \" + filename, response + \"\\n\\n-----------------------\\n\\nTRANSCRIPT:\\n\" + transcript, os.environ.get('EMAIL_PASSWORD')))\n",
    "\n",
    "                # UNCOMMENT TO SEND TO CORRECT EMAIL\n",
    "                if receiving_email_address:  # If an email address was found\n",
    "                    asyncio.create_task(send_email_async(os.environ.get('SENDING_EMAIL_ADDRESS'), receiving_email_address, \"FRED response for \" + filename, response + \"\\n\\n-----------------------\\n\\nTRANSCRIPT:\\n\" + transcript, os.environ.get('EMAIL_PASSWORD')))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Exception in fred_async: {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def whisper_and_fred(target_file:str, local_folder:str):\n",
    "    filename = await whisper_async(target_file, local_folder) # need to wait for whisper to finish running before firing off fred\n",
    "    response = await fred_async(filename + \".txt\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideally we would just load the audios into memory to avoid all this download nonsense. \n",
    "# However, whisper requires a file path, so we have to download the files to disk first.\n",
    "# Also, audios might be too big.\n",
    "def download_file(drive_service, file, local_folder):\n",
    "    # Download file\n",
    "    request = drive_service.files().get_media(fileId=file['id'])\n",
    "    fh = io.BytesIO()\n",
    "    downloader = MediaIoBaseDownload(fh, request)\n",
    "    done = False\n",
    "    print(\"Downloading file...\", file['name'])\n",
    "    while done is False:\n",
    "        status, done = downloader.next_chunk()\n",
    "    downloaded_file_path = os.path.join(local_folder, file['name'])\n",
    "    with io.open(downloaded_file_path, 'wb') as f:\n",
    "        print(\"Writing file...\", file['name'])\n",
    "        fh.seek(0)\n",
    "        f.write(fh.read())\n",
    "    \n",
    "    return downloaded_file_path\n",
    "\n",
    "\n",
    "async def download_file_async(drive_service, file, local_folder, loop):\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        file_path = await loop.run_in_executor(executor, download_file, drive_service, file, local_folder)\n",
    "        # Process downloaded file asynchronously here\n",
    "        print(\"Downloaded and processed\", file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded files: {'audios_scha': {'Recording_358.m4a', 'Recording_332.wav.txt', 'Recording_359.m4a', 'Email octopi 18072023.wav.txt', 'Octopi trust questions 26072023.wav.txt', 'Recording_323.wav.txt', 'Email octopi 18072023.m4a', 'Recording_330.wav.txt', 'Recording_334.wav.txt', 'Mantis support 26072023.wav.txt', 'Recording_323.m4a', 'Audio from â˜•', 'Recording_360.m4a', 'Recording_334.m4a', 'Recording_327.wav.txt', 'Recording_331.wav.txt', 'Recording_329.wav.txt', 'Recording_361.m4a', 'Recording_323.wav', 'Recording_334.wav', 'Recording_325.wav.txt', 'Recording_329.wav', 'Recording_325.m4a'}, 'audios_mike': {'Voice 004.m4a', 'Voice 004 - Copy.wav', 'Voice 003.wav.txt', 'Voice 002.m4a', 'Voice 003.m4a', 'Voice 004.wav.txt', 'Voice 003.wav', 'Voice 002.wav', 'Voice 004.wav', 'Voice 002.wav.txt', 'Voice 004 - Copy.m4a', 'Voice 004 - Copy.wav.txt'}, 'audios_clint': {'Voice 004.m4a', 'Voice 004.wav', 'Voice 004.wav.txt'}, 'audios_loren': {'Transcribe List.wav', 'TRanscribe ScreenRecorderProject73.wav', 'Transcribe PM discussion.m4a', 'Transcribe meeting with Elmien.m4a', 'Transcribe meeting.m4a', 'Transcribe List.m4a', 'Transcribe PM discussion.wav.txt', 'Transcribe meeting.wav.txt', 'Transcribe meeting with Elmien.wav.txt', 'TRanscribe ScreenRecorderProject73.wav.txt', 'Transcribe List.wav.txt', 'project_meeting_with_clint_camille.wav', 'project_meeting_with_clint_camille.wav.txt', 'Transcribe meeting.wav', 'Transcribe PM discussion.wav', 'project_meeting_with_clint_camille (Original).m4a', 'TRanscribe ScreenRecorderProject73.m4a', 'project_meeting_with_clint_camille (Original).wav.txt', 'Transcribe meeting with Elmien.wav'}, 'audios_josh': {'hoi.wav'}, 'audios_bart': {'Audio from Bi Africa', 'Voice 001.m4a', 'Voice 003.wav.txt', 'Voice 002.m4a', 'Voice 003.m4a', 'Voice 003.wav', 'Voice 002.wav.txt', 'Voice 001.wav.txt', 'Voice 002.wav', 'Voice 001.wav'}, 'audios_mom': {'Wilkes Road 2.m4a', 'Wilkes Road.m4a', 'Wilkes Road.wav.txt', 'Wilkes Road 2.wav', 'Wilkes Road 2.wav.txt', 'Wilkes Road.wav'}, 'audios_dad': {'Wilkes Road 4.wav.txt', 'Kwadukuza Rural.wav', 'Wilkes Road 4.wav', 'Wilkes Road 5.wav.txt', 'Wilkes Road 5.m4a', 'Wilkes Road 4.m4a', 'Kwadukuza Rural.m4a', 'Kwadukuza Rural.wav.txt', 'Wilkes Road 5.wav'}}\n",
      "Detected new file in audios_scha: Recording_357.m4a at 2023-08-12 14:20:28\n",
      "Downloading file... Recording_357.m4a\n",
      "Writing file... Recording_357.m4a\n",
      "Detected new file in audios_scha: Recording_355.m4a at 2023-08-12 14:20:36\n",
      "Downloading file... Recording_355.m4a\n",
      "Writing file... Recording_355.m4a\n",
      "Detected new file in audios_scha: Recording_354.m4a at 2023-08-12 14:20:38\n",
      "Downloading file... Recording_354.m4a\n",
      "Writing file... Recording_354.m4a\n",
      "Detected new file in audios_scha: Recording_353.m4a at 2023-08-12 14:20:42\n",
      "Downloading file... Recording_353.m4a\n",
      "Writing file... Recording_353.m4a\n",
      "Detected new file in audios_scha: Recording_351.m4a at 2023-08-12 14:20:47\n",
      "Downloading file... Recording_351.m4a\n",
      "Writing file... Recording_351.m4a\n",
      "Detected new file in audios_scha: Recording_296.m4a at 2023-08-12 14:20:50\n",
      "Downloading file... Recording_296.m4a\n",
      "Writing file... Recording_296.m4a\n",
      "Detected new file in audios_scha: Recording_294.m4a at 2023-08-12 14:20:53\n",
      "Downloading file... Recording_294.m4a\n",
      "Writing file... Recording_294.m4a\n",
      "Detected new file in audios_scha: Recording_350.m4a at 2023-08-12 14:20:55\n",
      "Downloading file... Recording_350.m4a\n",
      "Writing file... Recording_350.m4a\n",
      "Detected new file in audios_scha: Recording_349.m4a at 2023-08-12 14:20:57\n",
      "Downloading file... Recording_349.m4a\n",
      "Writing file... Recording_349.m4a\n",
      "Detected new file in audios_scha: Recording_348.m4a at 2023-08-12 14:21:02\n",
      "Downloading file... Recording_348.m4a\n",
      "Writing file... Recording_348.m4a\n",
      "Detected new file in audios_scha: Recording_347.m4a at 2023-08-12 14:21:09\n",
      "Downloading file... Recording_347.m4a\n",
      "Writing file... Recording_347.m4a\n",
      "Detected new file in audios_scha: Recording_346.m4a at 2023-08-12 14:21:16\n",
      "Downloading file... Recording_346.m4a\n",
      "Writing file... Recording_346.m4a\n",
      "Detected new file in audios_scha: Recording_345.m4a at 2023-08-12 14:21:20\n",
      "Downloading file... Recording_345.m4a\n",
      "Writing file... Recording_345.m4a\n",
      "Detected new file in audios_scha: Recording_344.m4a at 2023-08-12 14:21:24\n",
      "Downloading file... Recording_344.m4a\n",
      "Writing file... Recording_344.m4a\n",
      "Detected new file in audios_scha: Recording_343.m4a at 2023-08-12 14:21:30\n",
      "Downloading file... Recording_343.m4a\n",
      "Writing file... Recording_343.m4a\n",
      "Detected new file in audios_scha: Recording_342.m4a at 2023-08-12 14:21:34\n",
      "Downloading file... Recording_342.m4a\n",
      "Writing file... Recording_342.m4a\n",
      "Detected new file in audios_scha: Recording_341.m4a at 2023-08-12 14:21:38\n",
      "Downloading file... Recording_341.m4a\n",
      "Writing file... Recording_341.m4a\n",
      "Detected new file in audios_scha: Recording_340.m4a at 2023-08-12 14:21:43\n",
      "Downloading file... Recording_340.m4a\n",
      "Writing file... Recording_340.m4a\n",
      "Detected new file in audios_scha: transcription Recording_339.m4a at 2023-08-12 14:21:45\n",
      "Downloading file... transcription Recording_339.m4a\n",
      "Writing file... transcription Recording_339.m4a\n",
      "Detected new file in audios_scha: Recording_338.m4a at 2023-08-12 14:21:51\n",
      "Downloading file... Recording_338.m4a\n",
      "Writing file... Recording_338.m4a\n",
      "Detected new file in audios_scha: Recording_337.m4a at 2023-08-12 14:21:55\n",
      "Downloading file... Recording_337.m4a\n",
      "Writing file... Recording_337.m4a\n",
      "Detected new file in audios_scha: Recording_336.m4a at 2023-08-12 14:22:02\n",
      "Downloading file... Recording_336.m4a\n",
      "Writing file... Recording_336.m4a\n",
      "Detected new file in audios_scha: Recording_332.m4a at 2023-08-12 14:22:05\n",
      "Downloading file... Recording_332.m4a\n",
      "Writing file... Recording_332.m4a\n",
      "Detected new file in audios_scha: Recording_331.m4a at 2023-08-12 14:22:11\n",
      "Downloading file... Recording_331.m4a\n",
      "Writing file... Recording_331.m4a\n",
      "Detected new file in audios_scha: Recording_330.m4a at 2023-08-12 14:22:16\n",
      "Downloading file... Recording_330.m4a\n",
      "Writing file... Recording_330.m4a\n",
      "Detected new file in audios_scha: Recording_329.m4a at 2023-08-12 14:22:23\n",
      "Downloading file... Recording_329.m4a\n",
      "Writing file... Recording_329.m4a\n",
      "Detected new file in audios_scha: Recording_327.m4a at 2023-08-12 14:22:31\n",
      "Downloading file... Recording_327.m4a\n",
      "Writing file... Recording_327.m4a\n",
      "Detected new file in audios_scha: Octopi trust questions 26072023.m4a at 2023-08-12 14:22:41\n",
      "Downloading file... Octopi trust questions 26072023.m4a\n",
      "Writing file... Octopi trust questions 26072023.m4a\n",
      "Detected new file in audios_scha: Mantis support 26072023.m4a at 2023-08-12 14:22:46\n",
      "Downloading file... Mantis support 26072023.m4a\n",
      "Writing file... Mantis support 26072023.m4a\n",
      "Detected new file in audios_josh: Caltex Salt Rock.m4a at 2023-08-12 14:22:59\n",
      "Downloading file... Caltex Salt Rock.m4a\n",
      "Writing file... Caltex Salt Rock.m4a\n",
      "Detected new file in audios_josh: end_to_end_ML_example_audios at 2023-08-12 14:23:01\n",
      "Downloading file... end_to_end_ML_example_audios\n",
      "<HttpError 403 when requesting https://www.googleapis.com/drive/v3/files/11G8xyAH3kN5A_mCupHPzKvY3ztTcUCcV?alt=media returned \"Only files with binary content can be downloaded. Use Export with Docs Editors files.\". Details: \"[{'message': 'Only files with binary content can be downloaded. Use Export with Docs Editors files.', 'domain': 'global', 'reason': 'fileNotDownloadable', 'location': 'alt', 'locationType': 'parameter'}]\">\n",
      "Detected new file in audios_josh: recording_CH4_2.m4a at 2023-08-12 14:23:02\n",
      "Downloading file... recording_CH4_2.m4a\n",
      "Writing file... recording_CH4_2.m4a\n",
      "Detected new file in audios_josh: New Recording.m4a at 2023-08-12 14:23:12\n",
      "Downloading file... New Recording.m4a\n",
      "Writing file... New Recording.m4a\n",
      "Detected new file in audios_josh: Wilkes Road 12.m4a at 2023-08-12 14:23:14\n",
      "Downloading file... Wilkes Road 12.m4a\n",
      "Writing file... Wilkes Road 12.m4a\n",
      "Detected new file in audios_josh: Azusa Pacific University 8.m4a at 2023-08-12 14:23:26\n",
      "Downloading file... Azusa Pacific University 8.m4a\n",
      "Writing file... Azusa Pacific University 8.m4a\n",
      "Detected new file in audios_josh: Wilkes Road 9.m4a at 2023-08-12 14:23:30\n",
      "Downloading file... Wilkes Road 9.m4a\n",
      "Writing file... Wilkes Road 9.m4a\n",
      "Detected new file in audios_josh: Wilkes Road 7.m4a at 2023-08-12 14:23:32\n",
      "Downloading file... Wilkes Road 7.m4a\n",
      "Writing file... Wilkes Road 7.m4a\n",
      "Detected new file in audios_josh: Wilkes Road 6.m4a at 2023-08-12 14:23:33\n",
      "Downloading file... Wilkes Road 6.m4a\n",
      "Writing file... Wilkes Road 6.m4a\n",
      "Detected new file in audios_josh: Wilkes Road.m4a at 2023-08-12 14:23:35\n",
      "Downloading file... Wilkes Road.m4a\n",
      "Writing file... Wilkes Road.m4a\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 71\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[39mexcept\u001b[39;00m HttpError \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m     68\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAn HTTP error occurred: \u001b[39m\u001b[39m{\u001b[39;00merror\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 71\u001b[0m \u001b[39mawait\u001b[39;00m main() \u001b[39m# for notebook since event loop already created\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 65\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m                 downloaded_files[local_folder]\u001b[39m.\u001b[39madd(file[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m# only do this if it was downloaded successfully\u001b[39;00m\n\u001b[1;32m     63\u001b[0m                 \u001b[39m# process the file to .wav and run Fred - get GPT response and send email\u001b[39;00m\n\u001b[1;32m     64\u001b[0m                 \u001b[39m# asyncio.create_task(whisper_and_fred(target_file=file['name'], local_folder=local_folder))\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m             \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m) \u001b[39m# allows for progress to be made on another coroutine - namely, whisper_and_fred\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[39mexcept\u001b[39;00m HttpError \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m     68\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAn HTTP error occurred: \u001b[39m\u001b[39m{\u001b[39;00merror\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4/Frameworks/Python.framework/Versions/3.11/lib/python3.11/asyncio/tasks.py:639\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(delay, result)\u001b[0m\n\u001b[1;32m    635\u001b[0m h \u001b[39m=\u001b[39m loop\u001b[39m.\u001b[39mcall_later(delay,\n\u001b[1;32m    636\u001b[0m                     futures\u001b[39m.\u001b[39m_set_result_unless_cancelled,\n\u001b[1;32m    637\u001b[0m                     future, result)\n\u001b[1;32m    638\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 639\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m future\n\u001b[1;32m    640\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     h\u001b[39m.\u001b[39mcancel()\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# If modifying these SCOPES, delete the file token.pickle.\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive.readonly']\n",
    "\n",
    "async def main():\n",
    "    try:\n",
    "        \"\"\"Shows basic usage of the Drive v3 API.\n",
    "        Lists the names and ids of the first 10 files the user has access to.\n",
    "        \"\"\"\n",
    "        creds = None\n",
    "        # The file token.pickle stores the user's access and refresh tokens, and is\n",
    "        # created automatically when the authorization flow completes for the first\n",
    "        # time.\n",
    "        if os.path.exists('token.pickle'):\n",
    "            with open('token.pickle', 'rb') as token:\n",
    "                creds = pickle.load(token)\n",
    "        # If there are no (valid) credentials available, let the user log in.\n",
    "        if not creds or not creds.valid:\n",
    "            if creds and creds.expired and creds.refresh_token:\n",
    "                creds.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file('client_secret_782650429580-k51cnfcs0gmn6kdkn7t5elbchinpspo1.apps.googleusercontent.com.json', SCOPES)\n",
    "                creds = flow.run_local_server(port=0)\n",
    "            # Save the credentials for the next run\n",
    "            with open('token.pickle', 'wb') as token:\n",
    "                pickle.dump(creds, token)\n",
    "\n",
    "        drive_service = build('drive', 'v3', credentials=creds)\n",
    "        loop = asyncio.get_event_loop()\n",
    "        # Get a list of already downloaded files\n",
    "        downloaded_files = {local_folder: set(os.listdir(local_folder)) for local_folder in FOLDER_NAME_TO_FOLDER_ID.keys()}\n",
    "        print(\"Downloaded files:\", downloaded_files)\n",
    "\n",
    "        # Continuously poll Google Drive folder for new files\n",
    "        while True:\n",
    "            for local_folder, folder_id in FOLDER_NAME_TO_FOLDER_ID.items():\n",
    "                # print(local_folder)\n",
    "                request = drive_service.files().list(\n",
    "                q=\"'{}' in parents and trashed = false\".format(folder_id),\n",
    "                fields='nextPageToken, files(id, name)',\n",
    "                pageToken=None).execute()\n",
    "                \n",
    "                # Get all files in the Google Drive folder\n",
    "                all_files = request.get('files', [])\n",
    "                # print(\"All files currently in GD:\", all_files)\n",
    "\n",
    "                # Remove already downloaded files\n",
    "                files_to_download = [file for file in all_files if file['name'] not in downloaded_files[local_folder]]\n",
    "                # print(\"Files to download:\", files_to_download)\n",
    "                \n",
    "                # only for files which have not been downloaded\n",
    "                for file in files_to_download: # this is not perfectly ideal, since\n",
    "                    print(\"Detected new file in \" + local_folder + \": \" + file['name'] + \" at \" + datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "                    # loop.create_task(download_file_async(drive_service, file, local_folder, loop))\n",
    "\n",
    "                    try:\n",
    "                        downloaded_file_path = download_file(drive_service, file, local_folder) # this is blocking so we can't make it async\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "                    \n",
    "                    # Add file to the record of downloaded files so do we have to await\n",
    "                    downloaded_files[local_folder].add(file['name']) # only do this if it was downloaded successfully\n",
    "\n",
    "                    # process the file to .wav and run Fred - get GPT response and send email\n",
    "                    # asyncio.create_task(whisper_and_fred(target_file=file['name'], local_folder=local_folder))\n",
    "                await asyncio.sleep(1) # allows for progress to be made on another coroutine - namely, whisper_and_fred\n",
    "\n",
    "    except HttpError as error:\n",
    "        print(f\"An HTTP error occurred: {error}\")\n",
    "\n",
    "\n",
    "await main() # for notebook since event loop already created"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
